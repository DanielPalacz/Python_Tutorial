{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonusy\n",
    "\n",
    "## 1. Pobieranie skompresowanych plików"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instytut Podstaw Informatyki Polskie Akademii Nauk (IPIPAN) prowadzi badania nad językiem polskim w kontekście uczenia maszynowego (NLP - natural language processing). Udostępnia on pretrenowane przez siebie modele tzw. word embeddingów (model Word2Vec). Modele te znajdują się na stronie http://dsmodels.nlp.ipipan.waw.pl/ (Wybrane modele w postaci binarnej na dole strony).\n",
    "\n",
    "Modele te są plikami w postaci skompresowanej .zip. Gdybyśmy chcieli pobrać te - albo inne - pliki na potrzeby np. naszego programu w Pythonie moglibyśmy oczywiście zrobić to ręcznie. Da się to jednak zrobić również z poziomu Pythona co pozwala zautomatyzować pracę w sytuacji gdyby np. plików było zbyt dużo by opłacało się robić to ręcznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nkjp+wiki-lemmas-all-300-cbow-ns-50\"\n",
    "\n",
    "def get_and_extract_model(model_link):\n",
    "    model_response = requests.get(model_link, stream=True)\n",
    "    zipfile.ZipFile(BytesIO(model_response.content)).extractall(\"extracted_model_{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_link = \"http://dsmodels.nlp.ipipan.waw.pl/binmodels/{}.zip\".format(model_name)\n",
    "\n",
    "get_and_extract_model(model_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wypełnianie formularzy (logowanie lub filtrowanie wyników wyszukiwania)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wróćmy do strony https://quotes.toscrape.com/ . W prawym górnym rogu jest tam link do panelu logowania. Czasami podczas scrapingu potrzebne będzie zalogowanie się w tego typu panelu. Może również zdarzyć się potrzeba wypełnienia formularza żeby przefiltrować wyniki wyszukiwania, np. szukajac ofert na portalach aukcyjnych. \n",
    "\n",
    "W tym celu poznamy nową funkcję z biblioteki requests, która odpowiada żądaniu `POST` z protokołu HTTP i pozwala m.in. na wypełnianie formularzy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Należy zajrzeć do devtoolsów i znaleźć odpowiedni request w zakładce Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'username': 'my_login', 'password': 'my_password'}\n",
    "url = 'https://quotes.toscrape.com/login'\n",
    "resp = requests.post(url, data=data)\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
